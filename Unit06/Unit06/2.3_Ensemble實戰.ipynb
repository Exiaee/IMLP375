{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3129ab3d",
   "metadata": {},
   "source": [
    "# Ensemble/Voting Classification in Python with Scikit-Learn\n",
    "refï¼šhttps://www.kaggle.com/c/titanic/submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6b020b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7163b994",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "Testing Data:\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "training_data = pd.read_csv(\"data/train.csv\")\n",
    "testing_data = pd.read_csv(\"data/test.csv\")\n",
    "def get_nulls(training, testing):\n",
    "    print(\"Training Data:\")\n",
    "    print(pd.isnull(training).sum())\n",
    "    print(\"Testing Data:\")\n",
    "    print(pd.isnull(testing).sum())\n",
    "\n",
    "get_nulls(training_data, testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffd6109f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n",
      "Testing Data:\n",
      "PassengerId    0\n",
      "Pclass         0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop the cabin column, as there are too many missing values\n",
    "# Drop the ticket numbers too, as there are too many categories\n",
    "# Drop names as they won't really help predict survivors\n",
    "training_data.drop(labels = ['Cabin', 'Ticket', 'Name'], axis=1, inplace=True)\n",
    "testing_data.drop(labels = ['Cabin', 'Ticket', 'Name'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Taking the mean/average value would be impacted by the skew\n",
    "# so we should use the median value to impute missing values\n",
    "training_data[\"Age\"].fillna(training_data[\"Age\"].median(),inplace=True)\n",
    "testing_data[\"Age\"].fillna(testing_data[\"Age\"].median(), inplace=True)\n",
    "training_data[\"Embarked\"].fillna(\"S\", inplace = True)\n",
    "testing_data[\"Fare\"].fillna(testing_data[\"Fare\"].median(), inplace=True)\n",
    "get_nulls(training_data, testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19e4f59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22.  ]\n",
      " [38.  ]\n",
      " [26.  ]\n",
      " [35.  ]\n",
      " [35.  ]\n",
      " [28.  ]\n",
      " [54.  ]\n",
      " [ 2.  ]\n",
      " [27.  ]\n",
      " [14.  ]\n",
      " [ 4.  ]\n",
      " [58.  ]\n",
      " [20.  ]\n",
      " [39.  ]\n",
      " [14.  ]\n",
      " [55.  ]\n",
      " [ 2.  ]\n",
      " [28.  ]\n",
      " [31.  ]\n",
      " [28.  ]\n",
      " [35.  ]\n",
      " [34.  ]\n",
      " [15.  ]\n",
      " [28.  ]\n",
      " [ 8.  ]\n",
      " [38.  ]\n",
      " [28.  ]\n",
      " [19.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [40.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [66.  ]\n",
      " [28.  ]\n",
      " [42.  ]\n",
      " [28.  ]\n",
      " [21.  ]\n",
      " [18.  ]\n",
      " [14.  ]\n",
      " [40.  ]\n",
      " [27.  ]\n",
      " [28.  ]\n",
      " [ 3.  ]\n",
      " [19.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [18.  ]\n",
      " [ 7.  ]\n",
      " [21.  ]\n",
      " [49.  ]\n",
      " [29.  ]\n",
      " [65.  ]\n",
      " [28.  ]\n",
      " [21.  ]\n",
      " [28.5 ]\n",
      " [ 5.  ]\n",
      " [11.  ]\n",
      " [22.  ]\n",
      " [38.  ]\n",
      " [45.  ]\n",
      " [ 4.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [29.  ]\n",
      " [19.  ]\n",
      " [17.  ]\n",
      " [26.  ]\n",
      " [32.  ]\n",
      " [16.  ]\n",
      " [21.  ]\n",
      " [26.  ]\n",
      " [32.  ]\n",
      " [25.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [ 0.83]\n",
      " [30.  ]\n",
      " [22.  ]\n",
      " [29.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [17.  ]\n",
      " [33.  ]\n",
      " [16.  ]\n",
      " [28.  ]\n",
      " [23.  ]\n",
      " [24.  ]\n",
      " [29.  ]\n",
      " [20.  ]\n",
      " [46.  ]\n",
      " [26.  ]\n",
      " [59.  ]\n",
      " [28.  ]\n",
      " [71.  ]\n",
      " [23.  ]\n",
      " [34.  ]\n",
      " [34.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [21.  ]\n",
      " [33.  ]\n",
      " [37.  ]\n",
      " [28.  ]\n",
      " [21.  ]\n",
      " [28.  ]\n",
      " [38.  ]\n",
      " [28.  ]\n",
      " [47.  ]\n",
      " [14.5 ]\n",
      " [22.  ]\n",
      " [20.  ]\n",
      " [17.  ]\n",
      " [21.  ]\n",
      " [70.5 ]\n",
      " [29.  ]\n",
      " [24.  ]\n",
      " [ 2.  ]\n",
      " [21.  ]\n",
      " [28.  ]\n",
      " [32.5 ]\n",
      " [32.5 ]\n",
      " [54.  ]\n",
      " [12.  ]\n",
      " [28.  ]\n",
      " [24.  ]\n",
      " [28.  ]\n",
      " [45.  ]\n",
      " [33.  ]\n",
      " [20.  ]\n",
      " [47.  ]\n",
      " [29.  ]\n",
      " [25.  ]\n",
      " [23.  ]\n",
      " [19.  ]\n",
      " [37.  ]\n",
      " [16.  ]\n",
      " [24.  ]\n",
      " [28.  ]\n",
      " [22.  ]\n",
      " [24.  ]\n",
      " [19.  ]\n",
      " [18.  ]\n",
      " [19.  ]\n",
      " [27.  ]\n",
      " [ 9.  ]\n",
      " [36.5 ]\n",
      " [42.  ]\n",
      " [51.  ]\n",
      " [22.  ]\n",
      " [55.5 ]\n",
      " [40.5 ]\n",
      " [28.  ]\n",
      " [51.  ]\n",
      " [16.  ]\n",
      " [30.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [44.  ]\n",
      " [40.  ]\n",
      " [26.  ]\n",
      " [17.  ]\n",
      " [ 1.  ]\n",
      " [ 9.  ]\n",
      " [28.  ]\n",
      " [45.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [61.  ]\n",
      " [ 4.  ]\n",
      " [ 1.  ]\n",
      " [21.  ]\n",
      " [56.  ]\n",
      " [18.  ]\n",
      " [28.  ]\n",
      " [50.  ]\n",
      " [30.  ]\n",
      " [36.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [ 9.  ]\n",
      " [ 1.  ]\n",
      " [ 4.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [45.  ]\n",
      " [40.  ]\n",
      " [36.  ]\n",
      " [32.  ]\n",
      " [19.  ]\n",
      " [19.  ]\n",
      " [ 3.  ]\n",
      " [44.  ]\n",
      " [58.  ]\n",
      " [28.  ]\n",
      " [42.  ]\n",
      " [28.  ]\n",
      " [24.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [34.  ]\n",
      " [45.5 ]\n",
      " [18.  ]\n",
      " [ 2.  ]\n",
      " [32.  ]\n",
      " [26.  ]\n",
      " [16.  ]\n",
      " [40.  ]\n",
      " [24.  ]\n",
      " [35.  ]\n",
      " [22.  ]\n",
      " [30.  ]\n",
      " [28.  ]\n",
      " [31.  ]\n",
      " [27.  ]\n",
      " [42.  ]\n",
      " [32.  ]\n",
      " [30.  ]\n",
      " [16.  ]\n",
      " [27.  ]\n",
      " [51.  ]\n",
      " [28.  ]\n",
      " [38.  ]\n",
      " [22.  ]\n",
      " [19.  ]\n",
      " [20.5 ]\n",
      " [18.  ]\n",
      " [28.  ]\n",
      " [35.  ]\n",
      " [29.  ]\n",
      " [59.  ]\n",
      " [ 5.  ]\n",
      " [24.  ]\n",
      " [28.  ]\n",
      " [44.  ]\n",
      " [ 8.  ]\n",
      " [19.  ]\n",
      " [33.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [29.  ]\n",
      " [22.  ]\n",
      " [30.  ]\n",
      " [44.  ]\n",
      " [25.  ]\n",
      " [24.  ]\n",
      " [37.  ]\n",
      " [54.  ]\n",
      " [28.  ]\n",
      " [29.  ]\n",
      " [62.  ]\n",
      " [30.  ]\n",
      " [41.  ]\n",
      " [29.  ]\n",
      " [28.  ]\n",
      " [30.  ]\n",
      " [35.  ]\n",
      " [50.  ]\n",
      " [28.  ]\n",
      " [ 3.  ]\n",
      " [52.  ]\n",
      " [40.  ]\n",
      " [28.  ]\n",
      " [36.  ]\n",
      " [16.  ]\n",
      " [25.  ]\n",
      " [58.  ]\n",
      " [35.  ]\n",
      " [28.  ]\n",
      " [25.  ]\n",
      " [41.  ]\n",
      " [37.  ]\n",
      " [28.  ]\n",
      " [63.  ]\n",
      " [45.  ]\n",
      " [28.  ]\n",
      " [ 7.  ]\n",
      " [35.  ]\n",
      " [65.  ]\n",
      " [28.  ]\n",
      " [16.  ]\n",
      " [19.  ]\n",
      " [28.  ]\n",
      " [33.  ]\n",
      " [30.  ]\n",
      " [22.  ]\n",
      " [42.  ]\n",
      " [22.  ]\n",
      " [26.  ]\n",
      " [19.  ]\n",
      " [36.  ]\n",
      " [24.  ]\n",
      " [24.  ]\n",
      " [28.  ]\n",
      " [23.5 ]\n",
      " [ 2.  ]\n",
      " [28.  ]\n",
      " [50.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [19.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [ 0.92]\n",
      " [28.  ]\n",
      " [17.  ]\n",
      " [30.  ]\n",
      " [30.  ]\n",
      " [24.  ]\n",
      " [18.  ]\n",
      " [26.  ]\n",
      " [28.  ]\n",
      " [43.  ]\n",
      " [26.  ]\n",
      " [24.  ]\n",
      " [54.  ]\n",
      " [31.  ]\n",
      " [40.  ]\n",
      " [22.  ]\n",
      " [27.  ]\n",
      " [30.  ]\n",
      " [22.  ]\n",
      " [28.  ]\n",
      " [36.  ]\n",
      " [61.  ]\n",
      " [36.  ]\n",
      " [31.  ]\n",
      " [16.  ]\n",
      " [28.  ]\n",
      " [45.5 ]\n",
      " [38.  ]\n",
      " [16.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [29.  ]\n",
      " [41.  ]\n",
      " [45.  ]\n",
      " [45.  ]\n",
      " [ 2.  ]\n",
      " [24.  ]\n",
      " [28.  ]\n",
      " [25.  ]\n",
      " [36.  ]\n",
      " [24.  ]\n",
      " [40.  ]\n",
      " [28.  ]\n",
      " [ 3.  ]\n",
      " [42.  ]\n",
      " [23.  ]\n",
      " [28.  ]\n",
      " [15.  ]\n",
      " [25.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [22.  ]\n",
      " [38.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [40.  ]\n",
      " [29.  ]\n",
      " [45.  ]\n",
      " [35.  ]\n",
      " [28.  ]\n",
      " [30.  ]\n",
      " [60.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [24.  ]\n",
      " [25.  ]\n",
      " [18.  ]\n",
      " [19.  ]\n",
      " [22.  ]\n",
      " [ 3.  ]\n",
      " [28.  ]\n",
      " [22.  ]\n",
      " [27.  ]\n",
      " [20.  ]\n",
      " [19.  ]\n",
      " [42.  ]\n",
      " [ 1.  ]\n",
      " [32.  ]\n",
      " [35.  ]\n",
      " [28.  ]\n",
      " [18.  ]\n",
      " [ 1.  ]\n",
      " [36.  ]\n",
      " [28.  ]\n",
      " [17.  ]\n",
      " [36.  ]\n",
      " [21.  ]\n",
      " [28.  ]\n",
      " [23.  ]\n",
      " [24.  ]\n",
      " [22.  ]\n",
      " [31.  ]\n",
      " [46.  ]\n",
      " [23.  ]\n",
      " [28.  ]\n",
      " [39.  ]\n",
      " [26.  ]\n",
      " [21.  ]\n",
      " [28.  ]\n",
      " [20.  ]\n",
      " [34.  ]\n",
      " [51.  ]\n",
      " [ 3.  ]\n",
      " [21.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [33.  ]\n",
      " [28.  ]\n",
      " [44.  ]\n",
      " [28.  ]\n",
      " [34.  ]\n",
      " [18.  ]\n",
      " [30.  ]\n",
      " [10.  ]\n",
      " [28.  ]\n",
      " [21.  ]\n",
      " [29.  ]\n",
      " [28.  ]\n",
      " [18.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [19.  ]\n",
      " [28.  ]\n",
      " [32.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [42.  ]\n",
      " [17.  ]\n",
      " [50.  ]\n",
      " [14.  ]\n",
      " [21.  ]\n",
      " [24.  ]\n",
      " [64.  ]\n",
      " [31.  ]\n",
      " [45.  ]\n",
      " [20.  ]\n",
      " [25.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [ 4.  ]\n",
      " [13.  ]\n",
      " [34.  ]\n",
      " [ 5.  ]\n",
      " [52.  ]\n",
      " [36.  ]\n",
      " [28.  ]\n",
      " [30.  ]\n",
      " [49.  ]\n",
      " [28.  ]\n",
      " [29.  ]\n",
      " [65.  ]\n",
      " [28.  ]\n",
      " [50.  ]\n",
      " [28.  ]\n",
      " [48.  ]\n",
      " [34.  ]\n",
      " [47.  ]\n",
      " [48.  ]\n",
      " [28.  ]\n",
      " [38.  ]\n",
      " [28.  ]\n",
      " [56.  ]\n",
      " [28.  ]\n",
      " [ 0.75]\n",
      " [28.  ]\n",
      " [38.  ]\n",
      " [33.  ]\n",
      " [23.  ]\n",
      " [22.  ]\n",
      " [28.  ]\n",
      " [34.  ]\n",
      " [29.  ]\n",
      " [22.  ]\n",
      " [ 2.  ]\n",
      " [ 9.  ]\n",
      " [28.  ]\n",
      " [50.  ]\n",
      " [63.  ]\n",
      " [25.  ]\n",
      " [28.  ]\n",
      " [35.  ]\n",
      " [58.  ]\n",
      " [30.  ]\n",
      " [ 9.  ]\n",
      " [28.  ]\n",
      " [21.  ]\n",
      " [55.  ]\n",
      " [71.  ]\n",
      " [21.  ]\n",
      " [28.  ]\n",
      " [54.  ]\n",
      " [28.  ]\n",
      " [25.  ]\n",
      " [24.  ]\n",
      " [17.  ]\n",
      " [21.  ]\n",
      " [28.  ]\n",
      " [37.  ]\n",
      " [16.  ]\n",
      " [18.  ]\n",
      " [33.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [26.  ]\n",
      " [29.  ]\n",
      " [28.  ]\n",
      " [36.  ]\n",
      " [54.  ]\n",
      " [24.  ]\n",
      " [47.  ]\n",
      " [34.  ]\n",
      " [28.  ]\n",
      " [36.  ]\n",
      " [32.  ]\n",
      " [30.  ]\n",
      " [22.  ]\n",
      " [28.  ]\n",
      " [44.  ]\n",
      " [28.  ]\n",
      " [40.5 ]\n",
      " [50.  ]\n",
      " [28.  ]\n",
      " [39.  ]\n",
      " [23.  ]\n",
      " [ 2.  ]\n",
      " [28.  ]\n",
      " [17.  ]\n",
      " [28.  ]\n",
      " [30.  ]\n",
      " [ 7.  ]\n",
      " [45.  ]\n",
      " [30.  ]\n",
      " [28.  ]\n",
      " [22.  ]\n",
      " [36.  ]\n",
      " [ 9.  ]\n",
      " [11.  ]\n",
      " [32.  ]\n",
      " [50.  ]\n",
      " [64.  ]\n",
      " [19.  ]\n",
      " [28.  ]\n",
      " [33.  ]\n",
      " [ 8.  ]\n",
      " [17.  ]\n",
      " [27.  ]\n",
      " [28.  ]\n",
      " [22.  ]\n",
      " [22.  ]\n",
      " [62.  ]\n",
      " [48.  ]\n",
      " [28.  ]\n",
      " [39.  ]\n",
      " [36.  ]\n",
      " [28.  ]\n",
      " [40.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [24.  ]\n",
      " [19.  ]\n",
      " [29.  ]\n",
      " [28.  ]\n",
      " [32.  ]\n",
      " [62.  ]\n",
      " [53.  ]\n",
      " [36.  ]\n",
      " [28.  ]\n",
      " [16.  ]\n",
      " [19.  ]\n",
      " [34.  ]\n",
      " [39.  ]\n",
      " [28.  ]\n",
      " [32.  ]\n",
      " [25.  ]\n",
      " [39.  ]\n",
      " [54.  ]\n",
      " [36.  ]\n",
      " [28.  ]\n",
      " [18.  ]\n",
      " [47.  ]\n",
      " [60.  ]\n",
      " [22.  ]\n",
      " [28.  ]\n",
      " [35.  ]\n",
      " [52.  ]\n",
      " [47.  ]\n",
      " [28.  ]\n",
      " [37.  ]\n",
      " [36.  ]\n",
      " [28.  ]\n",
      " [49.  ]\n",
      " [28.  ]\n",
      " [49.  ]\n",
      " [24.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [44.  ]\n",
      " [35.  ]\n",
      " [36.  ]\n",
      " [30.  ]\n",
      " [27.  ]\n",
      " [22.  ]\n",
      " [40.  ]\n",
      " [39.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [35.  ]\n",
      " [24.  ]\n",
      " [34.  ]\n",
      " [26.  ]\n",
      " [ 4.  ]\n",
      " [26.  ]\n",
      " [27.  ]\n",
      " [42.  ]\n",
      " [20.  ]\n",
      " [21.  ]\n",
      " [21.  ]\n",
      " [61.  ]\n",
      " [57.  ]\n",
      " [21.  ]\n",
      " [26.  ]\n",
      " [28.  ]\n",
      " [80.  ]\n",
      " [51.  ]\n",
      " [32.  ]\n",
      " [28.  ]\n",
      " [ 9.  ]\n",
      " [28.  ]\n",
      " [32.  ]\n",
      " [31.  ]\n",
      " [41.  ]\n",
      " [28.  ]\n",
      " [20.  ]\n",
      " [24.  ]\n",
      " [ 2.  ]\n",
      " [28.  ]\n",
      " [ 0.75]\n",
      " [48.  ]\n",
      " [19.  ]\n",
      " [56.  ]\n",
      " [28.  ]\n",
      " [23.  ]\n",
      " [28.  ]\n",
      " [18.  ]\n",
      " [21.  ]\n",
      " [28.  ]\n",
      " [18.  ]\n",
      " [24.  ]\n",
      " [28.  ]\n",
      " [32.  ]\n",
      " [23.  ]\n",
      " [58.  ]\n",
      " [50.  ]\n",
      " [40.  ]\n",
      " [47.  ]\n",
      " [36.  ]\n",
      " [20.  ]\n",
      " [32.  ]\n",
      " [25.  ]\n",
      " [28.  ]\n",
      " [43.  ]\n",
      " [28.  ]\n",
      " [40.  ]\n",
      " [31.  ]\n",
      " [70.  ]\n",
      " [31.  ]\n",
      " [28.  ]\n",
      " [18.  ]\n",
      " [24.5 ]\n",
      " [18.  ]\n",
      " [43.  ]\n",
      " [36.  ]\n",
      " [28.  ]\n",
      " [27.  ]\n",
      " [20.  ]\n",
      " [14.  ]\n",
      " [60.  ]\n",
      " [25.  ]\n",
      " [14.  ]\n",
      " [19.  ]\n",
      " [18.  ]\n",
      " [15.  ]\n",
      " [31.  ]\n",
      " [ 4.  ]\n",
      " [28.  ]\n",
      " [25.  ]\n",
      " [60.  ]\n",
      " [52.  ]\n",
      " [44.  ]\n",
      " [28.  ]\n",
      " [49.  ]\n",
      " [42.  ]\n",
      " [18.  ]\n",
      " [35.  ]\n",
      " [18.  ]\n",
      " [25.  ]\n",
      " [26.  ]\n",
      " [39.  ]\n",
      " [45.  ]\n",
      " [42.  ]\n",
      " [22.  ]\n",
      " [28.  ]\n",
      " [24.  ]\n",
      " [28.  ]\n",
      " [48.  ]\n",
      " [29.  ]\n",
      " [52.  ]\n",
      " [19.  ]\n",
      " [38.  ]\n",
      " [27.  ]\n",
      " [28.  ]\n",
      " [33.  ]\n",
      " [ 6.  ]\n",
      " [17.  ]\n",
      " [34.  ]\n",
      " [50.  ]\n",
      " [27.  ]\n",
      " [20.  ]\n",
      " [30.  ]\n",
      " [28.  ]\n",
      " [25.  ]\n",
      " [25.  ]\n",
      " [29.  ]\n",
      " [11.  ]\n",
      " [28.  ]\n",
      " [23.  ]\n",
      " [23.  ]\n",
      " [28.5 ]\n",
      " [48.  ]\n",
      " [35.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [36.  ]\n",
      " [21.  ]\n",
      " [24.  ]\n",
      " [31.  ]\n",
      " [70.  ]\n",
      " [16.  ]\n",
      " [30.  ]\n",
      " [19.  ]\n",
      " [31.  ]\n",
      " [ 4.  ]\n",
      " [ 6.  ]\n",
      " [33.  ]\n",
      " [23.  ]\n",
      " [48.  ]\n",
      " [ 0.67]\n",
      " [28.  ]\n",
      " [18.  ]\n",
      " [34.  ]\n",
      " [33.  ]\n",
      " [28.  ]\n",
      " [41.  ]\n",
      " [20.  ]\n",
      " [36.  ]\n",
      " [16.  ]\n",
      " [51.  ]\n",
      " [28.  ]\n",
      " [30.5 ]\n",
      " [28.  ]\n",
      " [32.  ]\n",
      " [24.  ]\n",
      " [48.  ]\n",
      " [57.  ]\n",
      " [28.  ]\n",
      " [54.  ]\n",
      " [18.  ]\n",
      " [28.  ]\n",
      " [ 5.  ]\n",
      " [28.  ]\n",
      " [43.  ]\n",
      " [13.  ]\n",
      " [17.  ]\n",
      " [29.  ]\n",
      " [28.  ]\n",
      " [25.  ]\n",
      " [25.  ]\n",
      " [18.  ]\n",
      " [ 8.  ]\n",
      " [ 1.  ]\n",
      " [46.  ]\n",
      " [28.  ]\n",
      " [16.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [25.  ]\n",
      " [39.  ]\n",
      " [49.  ]\n",
      " [31.  ]\n",
      " [30.  ]\n",
      " [30.  ]\n",
      " [34.  ]\n",
      " [31.  ]\n",
      " [11.  ]\n",
      " [ 0.42]\n",
      " [27.  ]\n",
      " [31.  ]\n",
      " [39.  ]\n",
      " [18.  ]\n",
      " [39.  ]\n",
      " [33.  ]\n",
      " [26.  ]\n",
      " [39.  ]\n",
      " [35.  ]\n",
      " [ 6.  ]\n",
      " [30.5 ]\n",
      " [28.  ]\n",
      " [23.  ]\n",
      " [31.  ]\n",
      " [43.  ]\n",
      " [10.  ]\n",
      " [52.  ]\n",
      " [27.  ]\n",
      " [38.  ]\n",
      " [27.  ]\n",
      " [ 2.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [ 1.  ]\n",
      " [28.  ]\n",
      " [62.  ]\n",
      " [15.  ]\n",
      " [ 0.83]\n",
      " [28.  ]\n",
      " [23.  ]\n",
      " [18.  ]\n",
      " [39.  ]\n",
      " [21.  ]\n",
      " [28.  ]\n",
      " [32.  ]\n",
      " [28.  ]\n",
      " [20.  ]\n",
      " [16.  ]\n",
      " [30.  ]\n",
      " [34.5 ]\n",
      " [17.  ]\n",
      " [42.  ]\n",
      " [28.  ]\n",
      " [35.  ]\n",
      " [28.  ]\n",
      " [28.  ]\n",
      " [ 4.  ]\n",
      " [74.  ]\n",
      " [ 9.  ]\n",
      " [16.  ]\n",
      " [44.  ]\n",
      " [18.  ]\n",
      " [45.  ]\n",
      " [51.  ]\n",
      " [24.  ]\n",
      " [28.  ]\n",
      " [41.  ]\n",
      " [21.  ]\n",
      " [48.  ]\n",
      " [28.  ]\n",
      " [24.  ]\n",
      " [42.  ]\n",
      " [27.  ]\n",
      " [31.  ]\n",
      " [28.  ]\n",
      " [ 4.  ]\n",
      " [26.  ]\n",
      " [47.  ]\n",
      " [33.  ]\n",
      " [47.  ]\n",
      " [28.  ]\n",
      " [15.  ]\n",
      " [20.  ]\n",
      " [19.  ]\n",
      " [28.  ]\n",
      " [56.  ]\n",
      " [25.  ]\n",
      " [33.  ]\n",
      " [22.  ]\n",
      " [28.  ]\n",
      " [25.  ]\n",
      " [39.  ]\n",
      " [27.  ]\n",
      " [19.  ]\n",
      " [28.  ]\n",
      " [26.  ]\n",
      " [32.  ]]\n",
      "0     -0.502445\n",
      "1      0.786845\n",
      "2     -0.488854\n",
      "3      0.420730\n",
      "4     -0.486337\n",
      "         ...   \n",
      "886   -0.386671\n",
      "887   -0.044381\n",
      "888   -0.176263\n",
      "889   -0.044381\n",
      "890   -0.492378\n",
      "Name: Fare, Length: 891, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Fit the encoder on the data (Feature: Sex)\n",
    "encoder_1 = LabelEncoder()\n",
    "encoder_1.fit(training_data[\"Sex\"])\n",
    "\n",
    "# Transform and replace training data\n",
    "training_sex_encoded = encoder_1.transform(training_data[\"Sex\"])\n",
    "training_data[\"Sex\"] = training_sex_encoded\n",
    "test_sex_encoded = encoder_1.transform(testing_data[\"Sex\"])\n",
    "testing_data[\"Sex\"] = test_sex_encoded\n",
    "\n",
    "# Fit the encoder on the data (Feature: Embarked)\n",
    "encoder_2 = LabelEncoder()\n",
    "encoder_2.fit(training_data[\"Embarked\"])\n",
    "\n",
    "training_embarked_encoded = encoder_2.transform(training_data[\"Embarked\"])\n",
    "training_data[\"Embarked\"] = training_embarked_encoded\n",
    "testing_embarked_encoded = encoder_2.transform(testing_data[\"Embarked\"])\n",
    "testing_data[\"Embarked\"] = testing_embarked_encoded\n",
    "\n",
    "# Any value we want to reshape needs be turned into array first\n",
    "ages_train = np.array(training_data[\"Age\"]).reshape(-1, 1)\n",
    "fares_train = np.array(training_data[\"Fare\"]).reshape(-1, 1)\n",
    "ages_test = np.array(testing_data[\"Age\"]).reshape(-1, 1)\n",
    "fares_test = np.array(testing_data[\"Fare\"]).reshape(-1, 1)\n",
    "print(ages_train)\n",
    "\n",
    "# Scaler takes arrays\n",
    "scaler = StandardScaler()\n",
    "\n",
    "training_data[\"Age\"] = scaler.fit_transform(ages_train)\n",
    "training_data[\"Fare\"] = scaler.fit_transform(fares_train)\n",
    "testing_data[\"Age\"] = scaler.fit_transform(ages_test)\n",
    "testing_data[\"Fare\"] = scaler.fit_transform(fares_test)\n",
    "print(training_data[\"Fare\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65bd0090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Sex       Age  SibSp  Parch      Fare  Embarked\n",
      "0       3    1 -0.565736      1      0 -0.502445         2\n",
      "1       1    0  0.663861      1      0  0.786845         0\n",
      "2       3    0 -0.258337      0      0 -0.488854         2\n",
      "3       1    0  0.433312      1      0  0.420730         2\n",
      "4       3    1  0.433312      0      0 -0.486337         2\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Now to select our training/testing data\n",
    "X_features = training_data.drop(labels=['PassengerId', 'Survived'], axis=1)\n",
    "y_labels = training_data['Survived']\n",
    "\n",
    "print(X_features.head(5))\n",
    "print(y_labels.head(5))\n",
    "\n",
    "# Make the train/test data from validation\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_features, y_labels, test_size=0.1,random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5652bc34",
   "metadata": {},
   "source": [
    "## Simple Averaging Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cd452cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "LogReg_clf = LogisticRegression()\n",
    "DTree_clf = DecisionTreeClassifier()\n",
    "SVC_clf = SVC()\n",
    "\n",
    "LogReg_clf.fit(X_train, y_train)\n",
    "DTree_clf.fit(X_train, y_train)\n",
    "SVC_clf.fit(X_train, y_train)\n",
    "\n",
    "LogReg_pred = LogReg_clf.predict(X_val)\n",
    "DTree_pred = DTree_clf.predict(X_val)\n",
    "SVC_pred = SVC_clf.predict(X_val)\n",
    "\n",
    "averaged_preds = (LogReg_pred + DTree_pred + SVC_pred)//3\n",
    "acc = accuracy_score(y_val, averaged_preds)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d32100",
   "metadata": {},
   "source": [
    "## Bagging Classification Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62ac47a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7927134146341464\n",
      "0.8188719512195123\n",
      "0.8113719512195123\n",
      "0.7963719512195122\n"
     ]
    }
   ],
   "source": [
    "logreg_bagging_model = BaggingClassifier(base_estimator=LogReg_clf, n_estimators=50, random_state=12)\n",
    "dtree_bagging_model = BaggingClassifier(base_estimator=DTree_clf, n_estimators=50, random_state=12)\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=12)\n",
    "extra_trees = ExtraTreesClassifier(n_estimators=100, random_state=12)\n",
    "\n",
    "def bagging_ensemble(model):\n",
    "    k_folds = KFold(n_splits=20, random_state=12,shuffle=True)\n",
    "    results = cross_val_score(model, X_train, y_train, cv=k_folds)\n",
    "    print(results.mean())\n",
    "\n",
    "bagging_ensemble(logreg_bagging_model)\n",
    "bagging_ensemble(dtree_bagging_model)\n",
    "bagging_ensemble(random_forest)\n",
    "bagging_ensemble(extra_trees)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09094ea7",
   "metadata": {},
   "source": [
    "## Boosting Classification Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a6d48bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 20 estimators:\n",
      "0.8052134146341464\n",
      "Results for 40 estimators:\n",
      "0.8176524390243903\n",
      "Results for 60 estimators:\n",
      "0.8164329268292683\n",
      "Results for 80 estimators:\n",
      "0.8151524390243902\n",
      "Results for 100 estimators:\n",
      "0.8101524390243903\n"
     ]
    }
   ],
   "source": [
    "k_folds = KFold(n_splits=20, random_state=12,shuffle=True)\n",
    "num_estimators = [20, 40, 60, 80, 100]\n",
    "result_list = []\n",
    "\n",
    "for i in num_estimators:\n",
    "    ada_boost = AdaBoostClassifier(n_estimators=i, random_state=12)\n",
    "    results = cross_val_score(ada_boost, X_train, y_train, cv=k_folds)\n",
    "    print(\"Results for {} estimators:\".format(i))\n",
    "    print(results.mean())\n",
    "    result_list.append(results.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3efce717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x23c9ff4ae20>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"num_estimators\")\n",
    "plt.ylabel(\"result\")\n",
    "plt.scatter(num_estimators, result_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8290c946",
   "metadata": {},
   "source": [
    "## voting\\Stacking Classification Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "161a4960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.8333333333333334\n",
      "Log Loss is: 5.756516038980461\n",
      "F1 Score is: 0.7761194029850748\n"
     ]
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(estimators=[('SVC', SVC_clf), ('DTree', DTree_clf), ('LogReg', LogReg_clf)], voting='hard')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "preds = voting_clf.predict(X_val)\n",
    "acc = accuracy_score(y_val, preds)\n",
    "l_loss = log_loss(y_val, preds)\n",
    "f1 = f1_score(y_val, preds)\n",
    "\n",
    "print(\"Accuracy is: \" + str(acc))\n",
    "print(\"Log Loss is: \" + str(l_loss))\n",
    "print(\"F1 Score is: \" + str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aedc530e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.796286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.494391</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.817561</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.059694</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.508257</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.962353</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.049062</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.397241</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.335187</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.185430</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.104637</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.336334</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.049062</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.324253</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.510161</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.767741</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.104637</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.491874</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.394887</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.518805</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex       Age  SibSp  Parch      Fare  Embarked\n",
       "715       3    1 -0.796286      0      0 -0.494391         2\n",
       "319       1    0  0.817561      1      1  2.059694         0\n",
       "829       1    0  2.508257      0      0  0.962353         2\n",
       "79        3    0  0.049062      0      0 -0.397241         2\n",
       "484       1    1 -0.335187      1      0  1.185430         0\n",
       "..      ...  ...       ...    ...    ...       ...       ...\n",
       "241       3    0 -0.104637      1      0 -0.336334         1\n",
       "253       3    1  0.049062      1      0 -0.324253         2\n",
       "390       1    1  0.510161      1      2  1.767741         2\n",
       "667       3    1 -0.104637      0      0 -0.491874         2\n",
       "843       3    1  0.394887      0      0 -0.518805         0\n",
       "\n",
       "[801 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "646b37be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.497413</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.371370</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.512278</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.553537</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.464100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.204852</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.482475</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.598908</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.417492</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.204852</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.493455</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.740881</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.314435</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.701476</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.507796</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.204852</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.493455</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.204852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.236957</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass  Sex       Age  SibSp  Parch      Fare  Embarked\n",
       "0            892       3    1  0.386231      0      0 -0.497413         1\n",
       "1            893       3    0  1.371370      1      0 -0.512278         2\n",
       "2            894       2    1  2.553537      0      0 -0.464100         1\n",
       "3            895       3    1 -0.204852      0      0 -0.482475         2\n",
       "4            896       3    0 -0.598908      1      1 -0.417492         2\n",
       "..           ...     ...  ...       ...    ...    ...       ...       ...\n",
       "413         1305       3    1 -0.204852      0      0 -0.493455         2\n",
       "414         1306       1    0  0.740881      0      0  1.314435         0\n",
       "415         1307       3    1  0.701476      0      0 -0.507796         2\n",
       "416         1308       3    1 -0.204852      0      0 -0.493455         2\n",
       "417         1309       3    1 -0.204852      1      1 -0.236957         0\n",
       "\n",
       "[418 rows x 8 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c47e0aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 7)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = testing_data.drop(labels=['PassengerId'], axis=1)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c83d2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(columns=['PassengerId', 'Survived'])\n",
    "submission_df['PassengerId'] = testing_data['PassengerId']\n",
    "preds = voting_clf.predict(test)\n",
    "submission_df['Survived'] = preds\n",
    "submission_df.to_csv('submissions.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3ee129d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1e65df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
